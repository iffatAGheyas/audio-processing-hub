{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a02a4f-800d-4afd-9d59-b0556bfac665",
   "metadata": {},
   "source": [
    "# Module 1: Fundamentals of Sound and Digital Audio\n",
    "\n",
    "Welcome to Module 1 of the Audio Processing Tutorial!  \n",
    "In this module we will:\n",
    "\n",
    "- **Define** what sound is (pressure waves, amplitude, frequency)  \n",
    "- **Explore** how sound is digitised (sampling, bit-depth, quantisation noise)  \n",
    "- **Compare** common file formats (WAV, MP3, FLAC)  \n",
    "\n",
    "**By the end of this module you will be able to:**  \n",
    "1. Generate and listen to pure sine waves.  \n",
    "2. Visualise waveforms and understand sampling-rate effects.  \n",
    "3. Load audio at different sample rates and hear the quality differences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d673d-90d6-4cc4-843e-d1709de8bab4",
   "metadata": {},
   "source": [
    "## What Is Sound? <a id=\"what-is-sound\"></a>\n",
    "\n",
    "Sound is a mechanical wave that propagates through a medium (air, water, or solids) as oscillations of pressure.\n",
    "\n",
    "- **Pressure wave:** Alternating regions of compression (high pressure) and rarefaction (low pressure).  \n",
    "- **Amplitude (A):** The maximum pressure deviation from ambient—perceived as loudness.  \n",
    "- **Frequency (f):** Number of pressure oscillations per second (Hz)—perceived as pitch.  \n",
    "- **Waveform:** The shape of the pressure variation over time (e.g. sine, square, sawtooth), which determines timbre.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0bd6ed-e83c-421f-a009-79fd52e7a847",
   "metadata": {},
   "source": [
    "## Notebook Demos <a id=\"notebook-demos\"></a>\n",
    "\n",
    "In this section we will:\n",
    "\n",
    "1. **Load & play** our MP3 demo file.  \n",
    "2. **Visualise** its waveform at sample-level resolution.  \n",
    "3. **Compare** playback at different sampling rates to hear aliasing/quality differences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7dd93b-bc55-4be1-8fd5-c7d7d7dcbe2d",
   "metadata": {},
   "source": [
    "## Interactive Track Explorer\n",
    "\n",
    "In this cell you can **select** one of four audio clips and immediately:\n",
    "\n",
    "1. **Visualise** the first 0.5 s of its waveform  \n",
    "2. **Visualise** a mid-segment (5.0 – 5.5 s) if the clip is long enough  \n",
    "3. **Play** the entire track at its native sampling rate  \n",
    "\n",
    "---\n",
    "\n",
    "### How to use\n",
    "\n",
    "1. **Choose a track** from the **Select track** dropdown:  \n",
    "   - **Grusel Melodie** – a percussive, high-harmonic melody  \n",
    "   - **Jzwschscan** – a vocal snippet with sibilance  \n",
    "   - **Sweep (synthetic chirp)** – a pure tone sweep up to 20 kHz  \n",
    "   - **Ambient Music** – a low-energy background loop  \n",
    "\n",
    "2. As soon as you make a selection, the cell will clear its previous output and:  \n",
    "   - Plot the **first 0.5 seconds** of the waveform  \n",
    "   - Plot the **5.0–5.5 s window** (if available) to show how the texture evolves  \n",
    "   - Display a ▶️ Play button and start playback at the clip’s native sample rate  \n",
    "\n",
    "---\n",
    "\n",
    "### What you’ll see\n",
    "\n",
    "- **Waveform shape**: loud, transient-rich clips (e.g. Grusel Melodie) will show sharp peaks; ambient loops may appear almost flat in the first 0.5 s.  \n",
    "- **Mid-segment**: helps you compare steady state vs. attack sections.  \n",
    "- **Audio playback**: lets you immediately hear each clip at full fidelity.\n",
    "\n",
    "Experiment with different tracks to get a feel for how waveform shapes correlate with the sound you hear!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f012d44-6e06-46ab-a389-0fda32b0206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "\n",
    "# Mapping of display names to filenames\n",
    "track_options = {\n",
    "    'Grusel Melodie':         'grusel-melodie-305360.mp3',\n",
    "    'Jzwschscan':             'jzwschscan-28009.mp3',\n",
    "    'Sweep (synthetic chirp)': 'sweep2-92802.mp3',\n",
    "    'Ambient Music':          '22-musica-ambiente-67854.mp3'\n",
    "}\n",
    "\n",
    "def show_track(track_name):\n",
    "    clear_output(wait=True)\n",
    "    filename = track_options[track_name]\n",
    "    audio_path = Path('sounds') / filename\n",
    "    \n",
    "    # Load at native rate\n",
    "    y, sr = librosa.load(str(audio_path), sr=None, mono=True)\n",
    "    \n",
    "    # Plot first 0.5 s\n",
    "    duration_plot = 0.5\n",
    "    n_plot = int(sr * duration_plot)\n",
    "    t = np.linspace(0, duration_plot, n_plot, endpoint=False)\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    plt.plot(t, y[:n_plot])\n",
    "    plt.title(f'Waveform of \"{track_name}\" (first {duration_plot}s)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot a mid-segment (5.0–5.5 s) if long enough\n",
    "    if len(y) > sr * 5.5:\n",
    "        start_time, mid_dur = 5.0, 0.5\n",
    "        start_sample = int(start_time * sr)\n",
    "        n_mid = int(mid_dur * sr)\n",
    "        t_mid = np.linspace(start_time, start_time + mid_dur, n_mid, endpoint=False)\n",
    "        plt.figure(figsize=(8, 2))\n",
    "        plt.plot(t_mid, y[start_sample:start_sample + n_mid])\n",
    "        plt.title(f'Waveform of \"{track_name}\" ({start_time}–{start_time+mid_dur}s)')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.show()\n",
    "    \n",
    "    # Play full track\n",
    "    print(f'▶️ Playing \"{track_name}\" at {sr} Hz')\n",
    "    display(Audio(y, rate=sr, autoplay=True))\n",
    "\n",
    "widgets.interact(\n",
    "    show_track,\n",
    "    track_name=widgets.Dropdown(\n",
    "        options=list(track_options.keys()),\n",
    "        description='Select track:',\n",
    "        value='Grusel Melodie'\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9299bb8-d299-4180-aca5-1715ec211de3",
   "metadata": {},
   "source": [
    "## Interactive Resampling Demo (Play / Stop + Amplitude Plot)\n",
    "\n",
    "Use the controls below to select an audio track, enter any down-sampling rate in Hz, then click **Play** to hear the clip resampled to that rate (and plotted at the top). Click **Stop** to halt playback.\n",
    "\n",
    "---\n",
    "\n",
    "### How to use\n",
    "\n",
    "1. **Select a track** from the dropdown.  \n",
    "2. **Enter** a sampling rate (in Hz).  \n",
    "3. Click **Play** to:\n",
    "   - Resample via `ffmpeg` (through pydub),  \n",
    "   - Plot the **first 50 ms** of the resampled waveform,  \n",
    "   - Play back the entire clip at the same rate.  \n",
    "4. Click **Stop** to clear the plot and audio.\n",
    "\n",
    "---\n",
    "\n",
    "### Why “Ambient Music” sometimes looks and sounds unchanged\n",
    "\n",
    "If you choose **Ambient Music**, you’ll notice the amplitude plot remains a flat line whether you down-sample to 44 100 Hz or as low as 3 000 Hz—and you won’t hear any audible difference. That’s because this particular track begins with almost complete silence (or a very low-level fade-in), so the first 50 ms contain virtually no signal energy (see the first panel for Ambient Music at both 44 100 and 3 000 Hz :contentReference[oaicite:0]{index=0}). Down-sampling silence still yields silence!\n",
    "\n",
    "---\n",
    "\n",
    "### When you will hear a change\n",
    "\n",
    "To perceive the effect of different sampling rates, pick a clip with strong transient or high-frequency content:\n",
    "\n",
    "- **Grusel Melodie**: clear percussive attack, lots of high-frequency harmonics  \n",
    "- **Jzwschscan**: voice/vocal bursts with sibilance  \n",
    "- **Sweep (synthetic)**: a sine-sweep up into 20 kHz  \n",
    "\n",
    "As you lower the rate below half your target (the Nyquist limit), you’ll see the waveform “thin out” in the plot and hear loss of brightness or aliasing artifacts.  \n",
    "\n",
    "---\n",
    "\n",
    "### Recommended rate ranges\n",
    "\n",
    "- **≤ 8 000 Hz**: heavy high-end loss, thin/muffled or even silent if content is above 4 kHz  \n",
    "- **16 000–22 050 Hz**: speech-quality or telephone-quality — decent midrange but missing air  \n",
    "- **44 100 Hz**: CD-quality — full audible band  \n",
    "- **> 44 100 Hz**: no further audible benefit for most recordings  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ae91e-00a6-49d0-8700-21a3342302e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Audio, clear_output\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Map friendly names to filenames (just the basename; we'll prefix with sounds/)\n",
    "track_options = [\n",
    "    ('Grusel Melodie',       'grusel-melodie-305360.mp3'),\n",
    "    ('Jzwschscan',           'jzwschscan-28009.mp3'),\n",
    "    ('Sweep (synthetic)',    'sweep2-92802.mp3'),\n",
    "    ('Ambient Music',        '22-musica-ambiente-67854.mp3')\n",
    "]\n",
    "\n",
    "track_dropdown = widgets.Dropdown(\n",
    "    options=track_options,\n",
    "    description='Track:'\n",
    ")\n",
    "play_button = widgets.Button(description=\"Play\")\n",
    "stop_button = widgets.Button(description=\"Stop\")\n",
    "sampling_rate_input = widgets.IntText(value=44100, description=\"Rate (Hz):\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def play_audio(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        sr = sampling_rate_input.value\n",
    "        filename = track_dropdown.value\n",
    "        full_path = os.path.join('sounds', filename)        # ◀― load from sounds/\n",
    "        \n",
    "        # Load and resample via pydub/ffmpeg\n",
    "        audio = AudioSegment.from_file(full_path)\n",
    "        seg   = audio.set_frame_rate(sr)\n",
    "        \n",
    "        # Extract samples for plotting (first 50 ms)\n",
    "        samples = np.array(seg.get_array_of_samples())\n",
    "        if seg.channels == 2:\n",
    "            # use left channel for display\n",
    "            samples = samples.reshape((-1, 2))[:, 0]\n",
    "        n_plot       = int(sr * 0.05)\n",
    "        samples_plot = samples[:n_plot]\n",
    "        t = np.linspace(0, n_plot/sr, n_plot, endpoint=False)\n",
    "        \n",
    "        # Plot amplitude\n",
    "        plt.figure(figsize=(8, 2))\n",
    "        plt.plot(t, samples_plot)\n",
    "        track_label = os.path.splitext(filename)[0]\n",
    "        plt.title(f'{track_label} @ {sr} Hz (first 50 ms)')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.show()\n",
    "        \n",
    "        # Play the full resampled audio\n",
    "        buf = io.BytesIO()\n",
    "        seg.export(buf, format='wav')\n",
    "        buf.seek(0)\n",
    "        print(f\"▶️ Playing {track_label} at {sr} Hz\")\n",
    "        display(Audio(data=buf.read(), rate=sr, autoplay=True))\n",
    "\n",
    "def stop_audio(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(\"Audio stopped.\")\n",
    "\n",
    "play_button.on_click(play_audio)\n",
    "stop_button.on_click(stop_audio)\n",
    "\n",
    "display(\n",
    "    track_dropdown,\n",
    "    widgets.HBox([play_button, stop_button]),\n",
    "    sampling_rate_input,\n",
    "    output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43517ccd-62b8-4326-9305-574278a56fd0",
   "metadata": {},
   "source": [
    "### Pure‐Tone Generator & Waveform Visualiser (Text‐Box + Play/Stop)\n",
    "\n",
    "In this cell you can generate a custom sine wave by typing in a frequency (Hz) and an amplitude (0–1), then using **Play** and **Stop** to control playback. You’ll also see the first 5 ms of the waveform plotted above the audio player.\n",
    "\n",
    "**How to use**  \n",
    "1. Enter a **frequency** (Hz) in the **Freq** box.  \n",
    "2. Enter an **amplitude** (0–1) in the **Amp** box.  \n",
    "3. Click **Play** – the waveform for the first 5 ms appears and the tone plays.  \n",
    "4. Click **Stop** to halt playback and clear the plot.\n",
    "\n",
    "---\n",
    "\n",
    "#### Note on low frequencies  \n",
    "Although human hearing spans roughly 20 Hz–20 kHz, most laptop/phone speakers and our ears are **far less sensitive** below a few hundred Hz. If you enter a very low frequency (e.g. under **300 Hz**), you may not hear the tone clearly (or at all) unless you raise the amplitude. Try frequencies from **400 Hz** up to **10 kHz** for the best audibility on typical speakers.\n",
    "\n",
    "Experiment with different values to see how pitch (frequency) and loudness (amplitude) interact—and observe how the waveform changes on each play!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49d52ae-e639-4eed-8e6a-71ac5f3c25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Output area for plot + audio widget\n",
    "output = widgets.Output()\n",
    "\n",
    "# Text boxes for frequency and amplitude\n",
    "freq_input = widgets.IntText(\n",
    "    value=1000,\n",
    "    description='Freq (Hz):',\n",
    "    continuous_update=False\n",
    ")\n",
    "amp_input = widgets.FloatText(\n",
    "    value=0.5,\n",
    "    description='Amp (0–1):',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Play & Stop buttons\n",
    "play_button = widgets.Button(description='Play')\n",
    "stop_button = widgets.Button(description='Stop')\n",
    "\n",
    "def play_sine(b):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        sr = 44100\n",
    "        duration = 1.0  # seconds\n",
    "        t = np.linspace(0, duration, int(sr * duration), endpoint=False)\n",
    "        freq = freq_input.value\n",
    "        amp = amp_input.value\n",
    "        \n",
    "        # generate sine wave\n",
    "        y = amp * np.sin(2 * np.pi * freq * t)\n",
    "\n",
    "        # Plot first 5 ms\n",
    "        zoom_ms = 0.005\n",
    "        n_zoom = int(sr * zoom_ms)\n",
    "        plt.figure(figsize=(6, 2))\n",
    "        plt.plot(t[:n_zoom], y[:n_zoom])\n",
    "        plt.title(f'{freq} Hz sine @ amplitude {amp}')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.show()\n",
    "\n",
    "        # Play the tone\n",
    "        display(Audio(y, rate=sr, autoplay=True))\n",
    "\n",
    "def stop_sine(b):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        print(\"▶️ Playback stopped.\")\n",
    "\n",
    "play_button.on_click(play_sine)\n",
    "stop_button.on_click(stop_sine)\n",
    "\n",
    "# Display controls + output\n",
    "display(widgets.VBox([\n",
    "    freq_input,\n",
    "    amp_input,\n",
    "    widgets.HBox([play_button, stop_button]),\n",
    "    output\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd30db29-5840-426c-a82f-e2a695358ccf",
   "metadata": {},
   "source": [
    "## Sampling Theorem Visualiser\n",
    "\n",
    "**Nyquist sampling** is the rule that to capture (and later perfectly reconstruct) a signal containing frequencies up to *F* Hz, you must sample at least twice that rate—i.e. at *2F* samples per second.  \n",
    "\n",
    "> **In plain English:**  \n",
    "> - If you sample faster than twice the highest frequency in your sound, each “dot” (sample) lands exactly on the true waveform and you lose no information.  \n",
    "> - If you sample slower than twice that frequency, your samples can “miss” the peaks and troughs and trick you into reconstructing a completely wrong, lower-frequency signal. That mistake is called **aliasing**.  \n",
    "\n",
    "In the cell below you’ll see **three** subplots:\n",
    "\n",
    "1. **Continuous-time sine** (ideal)  \n",
    "   - A smooth 3 kHz sine wave at very high resolution.  \n",
    "2. **Sampled at Nyquist** (`fs = 2·f₀`, here 2×3 kHz = 6 kHz)  \n",
    "   - Blue circles and stems lie perfectly on the grey dashed sine—this is the minimum rate for exact reconstruction.  \n",
    "3. **Sampled below Nyquist** (`fs = 1·f₀`, here 1×3 kHz = 3 kHz)  \n",
    "   - Orange squares and stems no longer follow the sine, illustrating aliasing (peaks vanish or flip, even appearing as a DC line).\n",
    "\n",
    "**What to observe**  \n",
    "- Above or at Nyquist, sample points align with the continuous curve—**no loss** of information.  \n",
    "- Below Nyquist, sample points misrepresent the waveform—**aliasing** errors appear.\n",
    "\n",
    "**How to experiment**  \n",
    "- Edit the variables `f0`, `fs_above`, or `fs_below` in the code cell to try different signal or sampling frequencies.  \n",
    "- Re-run the cell (Shift + Enter) to see how changing the sampling rate moves you in and out of the alias-free region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fd3b42-32b5-402a-9478-0d83e080cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Signal parameters\n",
    "f0     = 3000.0       # signal frequency in Hz\n",
    "cycles = 3            # how many cycles to show\n",
    "duration = cycles / f0\n",
    "\n",
    "# Continuous‐time (ideal) sine\n",
    "t_cont = np.linspace(0, duration, 1000)\n",
    "y_cont = np.sin(2 * np.pi * f0 * t_cont)\n",
    "\n",
    "# Choose one rate above Nyquist (>2·f0) and one below (<2·f0)\n",
    "fs_above = 2.5 * f0   # above Nyquist\n",
    "fs_below = 1.5 * f0   # below Nyquist\n",
    "\n",
    "# Sampled signals\n",
    "t_above = np.arange(0, duration, 1/fs_above)\n",
    "y_above = np.sin(2 * np.pi * f0 * t_above)\n",
    "\n",
    "t_below = np.arange(0, duration, 1/fs_below)\n",
    "y_below = np.sin(2 * np.pi * f0 * t_below)\n",
    "\n",
    "# Plot them without shared x-axis so each is labelled\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 6), sharex=False)\n",
    "\n",
    "# 1) Continuous\n",
    "axes[0].plot(t_cont, y_cont, 'k')\n",
    "axes[0].set_xlim(0, duration)\n",
    "axes[0].set_xticks(np.linspace(0, duration, 4))\n",
    "axes[0].set_title('1) Continuous-time sine (ideal)')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "\n",
    "# 2) Sampled above Nyquist\n",
    "axes[1].plot(t_cont, y_cont, color='gray', linestyle='--', alpha=0.6)\n",
    "axes[1].stem(t_above, y_above, linefmt='C0-', markerfmt='C0o', basefmt='k-')\n",
    "axes[1].set_xlim(0, duration)\n",
    "axes[1].set_xticks(np.linspace(0, duration, 4))\n",
    "axes[1].set_title(f'2) Sampled above Nyquist (fs = {fs_above:.0f} Hz)')\n",
    "axes[1].set_ylabel('Amplitude')\n",
    "\n",
    "# 3) Sampled below Nyquist\n",
    "axes[2].plot(t_cont, y_cont, color='gray', linestyle='--', alpha=0.6)\n",
    "axes[2].stem(t_below, y_below, linefmt='C1-', markerfmt='C1s', basefmt='k-')\n",
    "axes[2].set_xlim(0, duration)\n",
    "axes[2].set_xticks(np.linspace(0, duration, 4))\n",
    "axes[2].set_title(f'3) Sampled below Nyquist (fs = {fs_below:.0f} Hz)')\n",
    "axes[2].set_xlabel('Time (s)')\n",
    "axes[2].set_ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b45e42-ffb4-4528-be2d-4ab5f82f276f",
   "metadata": {},
   "source": [
    "### Bit-Depth & Quantisation Noise Demo\n",
    "\n",
    "**What is a bit & bit-depth?**  \n",
    "- A **bit** is a binary digit that can be 0 or 1.  \n",
    "- **Bit-depth** tells you how many bits are used to represent each audio sample.  \n",
    "  - With **16-bit**, each sample can take one of 2¹⁶ (65 536) possible levels.  \n",
    "  - With **8-bit**, only 2⁸ (256) levels — much coarser steps.  \n",
    "  - Lower bit-depths mean fewer possible amplitude values, which introduces quantisation error (“steps”) and audible noise.\n",
    "\n",
    "---\n",
    "\n",
    "In this cell you can hear and see the effect of reducing the bit-depth on a clean 1 kHz sine wave:\n",
    "\n",
    "1. **Choose a bit-depth** from the dropdown (16, 8, 4 or 2 bits).  \n",
    "2. Click **Play** to generate a 1 kHz sine, quantise it to that bit-depth, plot the first 5 ms of the stepped waveform, and play back the result so you can hear the added “hiss” or distortion.\n",
    "\n",
    "#### What to observe\n",
    "- **16 bit**: nearly identical to the smooth sine (65 536 levels).  \n",
    "- **8 bit**: you’ll see distinct steps and hear a light quantisation hiss (256 levels).  \n",
    "- **4 bit**: coarse steps create noticeable distortion and more noise (16 levels).  \n",
    "- **2 bit**: only 4 levels — the tone is barely recognisable, dominated by quantisation noise.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128561a6-d225-4716-859b-d9674dd25a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Output area\n",
    "output = widgets.Output()\n",
    "\n",
    "# Widget controls\n",
    "bit_dropdown = widgets.Dropdown(\n",
    "    options=[('16-bit (no quant.)', 16),\n",
    "             ('8-bit', 8),\n",
    "             ('4-bit', 4),\n",
    "             ('2-bit', 2)],\n",
    "    value=16,\n",
    "    description='Bit-depth:'\n",
    ")\n",
    "play_button = widgets.Button(description='Play')\n",
    "\n",
    "def quantise_and_play(b):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        # Parameters\n",
    "        sr = 44100\n",
    "        duration = 1.0\n",
    "        freq = 1000.0\n",
    "        bits = bit_dropdown.value\n",
    "        \n",
    "        # Generate ideal sine\n",
    "        t = np.linspace(0, duration, int(sr*duration), endpoint=False)\n",
    "        y = np.sin(2*np.pi*freq*t)\n",
    "        \n",
    "        # Quantise to given bit-depth\n",
    "        levels = 2**bits\n",
    "        y_q = np.round((y + 1) * (levels/2 - 1)) / (levels/2 - 1) - 1\n",
    "        \n",
    "        # Plot first 5 ms\n",
    "        zoom = int(0.005 * sr)\n",
    "        plt.figure(figsize=(6,2))\n",
    "        plt.plot(t[:zoom], y[:zoom], 'k--', alpha=0.6, label='Original')\n",
    "        plt.step(t[:zoom], y_q[:zoom], 'C1', where='mid', label=f'{bits}-bit')\n",
    "        plt.title(f'1 kHz sine quantised to {bits}-bit')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "        \n",
    "        # Play quantised audio\n",
    "        print(f'▶️ Playing {bits}-bit quantised sine:')\n",
    "        display(Audio(y_q, rate=sr, autoplay=True))\n",
    "\n",
    "play_button.on_click(quantise_and_play)\n",
    "\n",
    "# Display UI\n",
    "display(widgets.VBox([bit_dropdown, play_button, output]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17847662-a23b-4ecf-b67c-7b3ba3c71859",
   "metadata": {},
   "source": [
    "### File-Format Comparison: WAV vs. MP3 vs. FLAC\n",
    "\n",
    "In this cell we take the **first 3 seconds** of our original MP3 clip and export it to three formats:\n",
    "\n",
    "1. **WAV (PCM)** – uncompressed, largest file size, perfect reproduction  \n",
    "2. **MP3 (lossy)** – smaller file size, may show compression artifacts (smearing, pre-echo)  \n",
    "3. **FLAC (lossless)** – compressed without any quality loss, moderate file size  \n",
    "\n",
    "**What to expect**  \n",
    "- WAV → largest size, crystal-clear sound  \n",
    "- MP3 → smallest size, listen for subtle artifacts  \n",
    "- FLAC → intermediate size, identical quality to WAV  \n",
    "\n",
    "**How it works**  \n",
    "1. We load the MP3 and take a 3 s snippet.  \n",
    "2. We export that snippet to WAV and FLAC using pydub/ffmpeg.  \n",
    "3. We display a small table of file sizes (in KB).  \n",
    "4. We embed three ▶️ players so you can A/B/C them back-to-back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4cc666-52ba-4d61-b526-df3faac980fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# 1) Load your ADPCM WAV into numpy (librosa handles decoding)\n",
    "y, sr = librosa.load('REC002.WAV', sr=None, mono=True)\n",
    "\n",
    "# 2) Convert float32 [-1,1] → int16 PCM\n",
    "y_int16 = np.int16(y * 32767)\n",
    "\n",
    "# 3) Build a pydub AudioSegment from raw PCM bytes\n",
    "segment = AudioSegment(\n",
    "    data=y_int16.tobytes(),\n",
    "    sample_width=2,      # 16-bit = 2 bytes\n",
    "    frame_rate=sr,\n",
    "    channels=1\n",
    ")\n",
    "\n",
    "# 4) Take a 3 s snippet\n",
    "clip = segment[:3000]    # first 3000 ms\n",
    "\n",
    "# 5) Export snippet to WAV (PCM), FLAC, MP3\n",
    "clip.export('snippet.wav',  format='wav')   # default is pcm_s16le\n",
    "clip.export('snippet.flac', format='flac')\n",
    "clip.export('snippet.mp3',  format='mp3')\n",
    "\n",
    "# 6) Gather file sizes\n",
    "files = {'WAV':'snippet.wav', 'MP3':'snippet.mp3', 'FLAC':'snippet.flac'}\n",
    "rows = []\n",
    "for fmt, fname in files.items():\n",
    "    size_kb = os.path.getsize(fname) / 1024\n",
    "    rows.append({'Format':fmt, 'Filename':fname, 'Size (KB)':f'{size_kb:.1f}'})\n",
    "df = pd.DataFrame(rows)\n",
    "display(df)\n",
    "\n",
    "# 7) Play each version (FLAC via librosa for compatibility)\n",
    "for fmt, fname in files.items():\n",
    "    size = df.loc[df.Format==fmt, 'Size (KB)'].values[0]\n",
    "    print(f'▶️ {fmt} ({size} KB)')\n",
    "    if fmt=='FLAC':\n",
    "        y2, sr2 = librosa.load(fname, sr=None, mono=True)\n",
    "        display(Audio(y2, rate=sr2, autoplay=True))\n",
    "    else:\n",
    "        display(Audio(filename=fname, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a7a039-e119-421c-b1e3-ed69efcf905c",
   "metadata": {},
   "source": [
    "### Exercise: Record & Resample\n",
    "\n",
    "1. **Record** a 3-second audio clip on your phone and upload it to this notebook directory (e.g. `your_clip.wav`).  \n",
    "2. **Run** the cell below to:\n",
    "   - **Load** your clip at its native rate  \n",
    "   - **Plot** the original waveform (first 0.5 s)  \n",
    "   - **Play** the original audio  \n",
    "   - **Down-sample** to 8 kHz  \n",
    "   - **Plot** the down-sampled waveform (first 0.5 s)  \n",
    "   - **Play** the down-sampled audio  \n",
    "3. **Compare** the two players—note the loss of high-frequency detail and any aliasing artifacts.\n",
    "\n",
    "## Module 1: Summary & Quiz\n",
    "\n",
    "**Key take-aways**  \n",
    "- **Sound** is a pressure wave characterised by **amplitude** (loudness) and **frequency** (pitch).  \n",
    "- **Nyquist theorem**: to capture all information, sample at least twice the highest frequency present.  \n",
    "- **Bit-depth** determines how many discrete amplitude levels you can represent—lower bit-depth adds quantisation noise (“hiss”).  \n",
    "- **Resampling** to lower rates removes content above the new Nyquist limit, causing audio to sound dull or aliased.  \n",
    "- **File formats**:  \n",
    "  - **WAV** is uncompressed PCM.  \n",
    "  - **FLAC** is lossless compressed PCM.  \n",
    "  - **MP3** is lossy—once detail is lost, converting back to WAV/FLAC cannot restore it.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick quiz**\n",
    "\n",
    "1. **What happens** if you sample a 10 kHz sine wave at 15 kHz?  \n",
    "   - A) Perfect reconstruction  \n",
    "   - B) Aliasing → lower-frequency error  \n",
    "   - C) No sound  \n",
    "\n",
    "2. **Why** does a lower bit-depth introduce “hiss” into audio?  \n",
    "   *(Short answer)*  \n",
    "\n",
    "3. **True or False**: Converting an MP3 to WAV will improve its audio quality.  \n",
    "\n",
    "> Submit your answers below or check the next cell for solutions!  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbf30c9-6aa5-4eb9-8377-ac33bb8aa9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# 1) Load your clip\n",
    "filename = 'REC002.WAV'    # ← change this to your uploaded file\n",
    "y, sr = librosa.load(filename, sr=None, mono=True)\n",
    "\n",
    "# 2) Plot & play original (first 0.5 s)\n",
    "t0 = np.linspace(0, 0.5, int(sr*0.5), endpoint=False)\n",
    "plt.figure(figsize=(8,2))\n",
    "plt.plot(t0, y[:len(t0)])\n",
    "plt.title('Original waveform (first 0.5 s)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n",
    "print(f'▶️ Playing original at {sr} Hz')\n",
    "display(Audio(y, rate=sr, autoplay=True))\n",
    "\n",
    "# 3) Down-sample to 8 kHz and plot & play\n",
    "y_8k = librosa.resample(y, orig_sr=sr, target_sr=8000)\n",
    "t1 = np.linspace(0, 0.5, int(8000*0.5), endpoint=False)\n",
    "plt.figure(figsize=(8,2))\n",
    "plt.plot(t1, y_8k[:len(t1)])\n",
    "plt.title('Down-sampled waveform @ 8 kHz (first 0.5 s)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n",
    "print('▶️ Playing down-sampled at 8 kHz')\n",
    "display(Audio(y_8k, rate=8000, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b120ecc-b725-4572-9518-928d2f827bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
