{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07cbc3c-52ee-4db2-963a-50e0501f37ab",
   "metadata": {},
   "source": [
    "## Module 5: Pre-processing Techniques\n",
    "\n",
    "In this module we’ll explore common audio “clean-up” and conditioning methods used before further analysis or synthesis.\n",
    "\n",
    "### Key Concepts\n",
    "- **Denoising**  \n",
    "  - Spectral subtraction  \n",
    "  - Wiener filtering  \n",
    "- **Normalization & Dynamic Range Compression**  \n",
    "  - Peak vs. RMS normalization  \n",
    "  - Compressor parameters: threshold, ratio, attack/release  \n",
    "- **Filtering**  \n",
    "  - FIR vs. IIR filters  \n",
    "  - Window design (Hamming, Blackman, etc.)  \n",
    "\n",
    "---\n",
    "\n",
    "### 📓 Notebook Demos\n",
    "\n",
    "1. **Spectral Subtraction Denoising**  \n",
    "   - Manually set your noise segment and subtraction gain in the code  \n",
    "   - Observe the cleaned waveform and spectrum  \n",
    "\n",
    "2. **Wiener-Filter Denoising**  \n",
    "   - Use the same noise estimate to design a Wiener filter  \n",
    "   - Compare audio and spectrograms to see the differences  \n",
    "\n",
    "3. **Dynamic Range Compression**  \n",
    "   - Manually set compressor threshold, ratio, attack & release in code  \n",
    "   - Play back and plot gain-reduction curves  \n",
    "\n",
    "4. **FIR vs. IIR Filtering & Window Design**  \n",
    "   - In a final demo cell, specify cutoff, filter type, and window (in code)  \n",
    "   - Plot impulse responses and magnitude responses of:  \n",
    "     - An FIR low-pass (using Hamming, Blackman, etc.)  \n",
    "     - An IIR Butterworth low-pass  \n",
    "   - Apply each to a test clip and play the results  \n",
    "\n",
    "---\n",
    "\n",
    "### 🛠 Exercise: Mains-Hum Removal Filter\n",
    "- **Task:** Implement a band-stop (notch) filter at 50 Hz (or 60 Hz) to remove mains hum from a voice recording.  \n",
    "- **Steps:**  \n",
    "  1. Design a narrow IIR notch filter centered at the line frequency.  \n",
    "  2. Apply it to a WAV file containing speech + hum.  \n",
    "  3. Compare spectra and audio before/after filtering.  \n",
    "- **Deliverable:**  \n",
    "  - Plot the magnitude response of your notch filter  \n",
    "  - Show spectrograms pre-/post-filter  \n",
    "  - Include audio players for before/after listening  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f6a90f-3939-4916-bfcc-2b95a3adf8ed",
   "metadata": {},
   "source": [
    "### Key Concepts: Denoising\n",
    "\n",
    "Before diving into the hands-on demos, it’s important to understand the two primary denoising strategies we’ll be exploring:\n",
    "\n",
    "- **Spectral Subtraction**  \n",
    "  1. **Noise Estimate:**  You first select a short “noise-only” segment of your recording (silence plus background noise).  \n",
    "  2. **Spectrum Subtraction:**  Compute the magnitude spectrum of that noise segment, then subtract it (often scaled by a user-controlled gain) from the magnitude spectrum of the full signal.  \n",
    "  3. **Reconstruction:**  Combine the cleaned magnitude with the original phase and invert back to the time domain.  \n",
    "  <br>  \n",
    "  **Key Points:**  \n",
    "  - Easy to implement and tune via a single “subtraction gain.”  \n",
    "  - Can produce musical noise (artifacts) if over-subtracted.\n",
    "\n",
    "- **Wiener Filtering**  \n",
    "  1. **Signal & Noise PSD:**  Estimate the power spectral density (PSD) of both the noise and the noisy signal.  \n",
    "  2. **Filter Design:**  Compute a frequency-dependent gain \\(H(f)\\) that minimizes mean-square error between the clean and estimated signals.  \n",
    "     \\[\n",
    "       H(f) \\;=\\; \\frac{S_{xx}(f)}{S_{xx}(f) + S_{nn}(f)}\n",
    "     \\]\n",
    "     where \\(S_{xx}\\) is the clean-signal PSD and \\(S_{nn}\\) is the noise PSD.  \n",
    "  3. **Apply & Reconstruct:**  Multiply the noisy signal’s spectrum by \\(H(f)\\), then invert to time domain.  \n",
    "  <br>  \n",
    "  **Key Points:**  \n",
    "  - Statistically optimal under Gaussian noise assumptions.  \n",
    "  - Tends to introduce fewer “musical” artifacts than spectral subtraction, but may sound “muffled” if PSD estimates are poor.\n",
    "\n",
    "In the upcoming demos you’ll manually set the noise estimate and filter parameters in the code, then compare the results of spectral subtraction vs. Wiener filtering on a noisy clip.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905bc85b-daa4-4ad7-933a-05ec898d4d2e",
   "metadata": {},
   "source": [
    "## Demo 1: Spectral Subtraction Denoising\n",
    "\n",
    "In this demo you’ll remove a stationary noise floor from an audio clip using **spectral subtraction**.\n",
    "\n",
    "### What the code does\n",
    "1. **Loads** your noisy audio file.  \n",
    "2. **Computes** an STFT to extract magnitude & phase.  \n",
    "3. **Estimates** the average noise spectrum from a user-specified noise-only segment.  \n",
    "4. **Subtracts** (with gain) that noise spectrum from every frame’s magnitude.  \n",
    "5. **Reconstructs** the denoised waveform by combining the cleaned magnitudes with the original phase.  \n",
    "6. **Plays back** both the noisy input and the denoised output.  \n",
    "7. **Plots** time-domain waveforms (before vs. after) and average magnitude spectra.  \n",
    "\n",
    "---\n",
    "\n",
    "### How to use\n",
    "1. **Edit the USER SETTINGS** at the top of the code cell:  \n",
    "   - `FILENAME` – your noisy clip in `sounds/` (supports WAV/MP3).  \n",
    "   - `NOISE_START`, `NOISE_END` – start/end times (s) of a pure noise segment.  \n",
    "   - `SUB_GAIN` – subtraction gain (e.g. 0.5…2.0).  \n",
    "   - `N_FFT` / `HOP_LENGTH` – STFT window & hop sizes (powers of two recommended).  \n",
    "2. **Run** the cell.  \n",
    "\n",
    "---\n",
    "\n",
    "### What to observe\n",
    "\n",
    "#### Audio\n",
    "- Does the **denoised** version sound cleaner?  \n",
    "- Are any artifacts (“musical noise”) introduced when you increase `SUB_GAIN`?\n",
    "\n",
    "#### Waveforms\n",
    "- The denoised signal should show **reduced background noise** in quiet regions.\n",
    "\n",
    "#### Spectra\n",
    "- The average magnitude spectrum after subtraction should have a **lowered noise floor** across frequencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07130918-51c3-4733-8b41-93e36835f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── USER SETTINGS ────────────────────────────────────────────────────────────────\n",
    "FILENAME      = 'noisy_clip.mp3'   # ← place your noisy audio clip in `sounds/`\n",
    "NOISE_START   = 0.0                # ← start time (s) of a noise-only segment\n",
    "NOISE_END     = 0.5                # ← end time (s) of the noise-only segment\n",
    "SUB_GAIN      = 1.0                # ← subtraction gain (e.g. 0.5…2.0)\n",
    "N_FFT         = 1024               # ← FFT window size\n",
    "HOP_LENGTH    = N_FFT // 4         # ← hop length for STFT\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from IPython.display import Audio, display\n",
    "from pathlib import Path\n",
    "\n",
    "# ── CONFIG (don’t edit below here) ───────────────────────────────────────────────\n",
    "SOUNDS_DIR = Path('sounds')\n",
    "audio_path = SOUNDS_DIR / FILENAME\n",
    "\n",
    "# 1) Load audio\n",
    "y, sr = librosa.load(str(audio_path), sr=None)\n",
    "\n",
    "# 2) Compute STFT\n",
    "D      = librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "mag    = np.abs(D)\n",
    "phase  = np.angle(D)\n",
    "\n",
    "# 3) Estimate noise spectrum from noise-only segment\n",
    "start_frame = int(NOISE_START * sr / HOP_LENGTH)\n",
    "end_frame   = int(NOISE_END   * sr / HOP_LENGTH)\n",
    "noise_mag   = mag[:, start_frame:end_frame].mean(axis=1, keepdims=True)\n",
    "\n",
    "# 4) Spectral subtraction\n",
    "mag_clean = mag - SUB_GAIN * noise_mag\n",
    "mag_clean = np.clip(mag_clean, a_min=0.0, a_max=None)\n",
    "\n",
    "# 5) Reconstruct complex spectrogram and invert to time-domain\n",
    "D_clean = mag_clean * np.exp(1j * phase)\n",
    "y_clean = librosa.istft(D_clean, hop_length=HOP_LENGTH)\n",
    "\n",
    "# 6) Display audio players\n",
    "print(\"▶️ Original (Noisy) Audio\")\n",
    "display(Audio(data=y,       rate=sr, autoplay=False))\n",
    "print(\"▶️ Denoised Audio\")\n",
    "display(Audio(data=y_clean, rate=sr, autoplay=False))\n",
    "\n",
    "# 7) Plot time-domain waveforms\n",
    "times = np.linspace(0, len(y)/sr, len(y))\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(times, y,       label='Noisy', alpha=0.7)\n",
    "plt.plot(times, y_clean, label='Denoised', alpha=0.7)\n",
    "plt.title('Waveform: Before vs. After Spectral Subtraction')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8) Plot magnitude spectra (averaged over time)\n",
    "mag_orig_mean = mag.mean(axis=1)\n",
    "mag_clean_mean = mag_clean.mean(axis=1)\n",
    "freqs = np.linspace(0, sr/2, len(mag_orig_mean))\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(freqs, 20*np.log10(mag_orig_mean+1e-8),   label='Noisy', alpha=0.7)\n",
    "plt.plot(freqs, 20*np.log10(mag_clean_mean+1e-8), label='Denoised', alpha=0.7)\n",
    "plt.title('Average Magnitude Spectrum: Before vs. After')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude (dB)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59915e3-0bb7-453e-9a32-87b00356c244",
   "metadata": {},
   "source": [
    "## Demo 2: Wiener‐Filter Denoising\n",
    "\n",
    "In this demo you’ll apply a classical Wiener filter to reduce stationary noise in an audio clip.\n",
    "\n",
    "**What the code does:**  \n",
    "1. **Loads** your noisy audio file.  \n",
    "2. **Computes** its STFT (magnitude & phase).  \n",
    "3. **Estimates** the average noise spectrum from your specified noise-only segment.  \n",
    "4. **Designs** a Wiener gain mask:  \n",
    "   \\[\n",
    "     G(k,n) = \\frac{|S(k,n)|^2}{|S(k,n)|^2 + |N(k)|^2}\n",
    "   \\]\n",
    "5. **Applies** the gain mask to the complex spectrogram and reconstructs the time-domain signal.  \n",
    "6. **Plays back** both the original noisy clip and the Wiener-denoised result.  \n",
    "7. **Plots** side-by-side log-frequency spectrograms before vs. after filtering.\n",
    "\n",
    "---\n",
    "\n",
    "### How to use\n",
    "\n",
    "1. **Edit the USER SETTINGS** at the top of the code cell:  \n",
    "   - `FILENAME` – your noisy clip in the `sounds/` folder (WAV or MP3)  \n",
    "   - `NOISE_START`, `NOISE_END` – start/end times (seconds) of a purely noise segment  \n",
    "   - `N_FFT` – STFT window size (power of two)  \n",
    "   - `HOP_LENGTH` – hop size between frames (usually `N_FFT/4`)  \n",
    "\n",
    "2. **Run the cell** to perform the Wiener filtering.\n",
    "\n",
    "---\n",
    "\n",
    "### What to observe\n",
    "\n",
    "- **Audio:**  \n",
    "  - ▶️ Play the **Original (Noisy)** and **Wiener-Denoised** versions.  \n",
    "  - Listen for reduced hiss or background noise, and note any filtering artifacts.\n",
    "\n",
    "- **Spectrograms:**  \n",
    "  - The **Noisy** spectrogram shows broadband noise across frequencies.  \n",
    "  - The **Wiener-Denoised** spectrogram should exhibit attenuated noise floor and cleaner harmonic structures.\n",
    "\n",
    "- **Trade-off:**  \n",
    "  - Strong noise reduction may introduce “musical noise” or distort transients.  \n",
    "  - Experiment with different noise segments and STFT settings to balance denoising vs. artifacting.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86f8b86-f844-4b58-b608-43546ef9b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── USER SETTINGS ────────────────────────────────────────────────────────────────\n",
    "FILENAME     = 'noisy_clip.mp3'   # ← place your noisy clip in `sounds/` (WAV or MP3)\n",
    "NOISE_START  = 0.0                # ← start time (s) of a noise-only segment\n",
    "NOISE_END    = 0.5                # ← end time (s) of the noise-only segment\n",
    "N_FFT        = 1024               # ← STFT window size (power of two)\n",
    "HOP_LENGTH   = N_FFT // 4         # ← hop length for STFT\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio, display\n",
    "from pathlib import Path\n",
    "\n",
    "# ── CONFIG (don’t edit below here) ───────────────────────────────────────────────\n",
    "SOUNDS_DIR = Path('sounds')\n",
    "audio_path = SOUNDS_DIR / FILENAME\n",
    "\n",
    "# 1) Load audio\n",
    "y, sr = librosa.load(str(audio_path), sr=None)\n",
    "\n",
    "# 2) Compute STFT\n",
    "D      = librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "mag    = np.abs(D)\n",
    "phase  = np.angle(D)\n",
    "\n",
    "# 3) Estimate noise spectrum\n",
    "start_frame = int(NOISE_START * sr / HOP_LENGTH)\n",
    "end_frame   = int(NOISE_END   * sr / HOP_LENGTH)\n",
    "noise_mag   = mag[:, start_frame:end_frame].mean(axis=1, keepdims=True)\n",
    "\n",
    "# 4) Design and apply Wiener filter\n",
    "#    Wiener gain = |S|^2 / (|S|^2 + |N|^2)\n",
    "gain = (mag**2) / (mag**2 + noise_mag**2 + 1e-8)\n",
    "D_wiener = gain * D\n",
    "y_wiener = librosa.istft(D_wiener, hop_length=HOP_LENGTH)\n",
    "\n",
    "# 5) Audio playback\n",
    "print(\"▶️ Original (Noisy) Audio\")\n",
    "display(Audio(data=y,         rate=sr, autoplay=False))\n",
    "print(\"▶️ Wiener-Denoised Audio\")\n",
    "display(Audio(data=y_wiener,  rate=sr, autoplay=False))\n",
    "\n",
    "# 6) Plot spectrograms\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "\n",
    "# Original spectrogram\n",
    "S_db = librosa.amplitude_to_db(mag, ref=np.max)\n",
    "librosa.display.specshow(S_db, sr=sr, hop_length=HOP_LENGTH, \n",
    "                         x_axis='time', y_axis='log', ax=ax[0])\n",
    "ax[0].set_title('Noisy Spectrogram')\n",
    "ax[0].invert_yaxis()\n",
    "\n",
    "# Wiener-denoised spectrogram\n",
    "mag_wiener = np.abs(D_wiener)\n",
    "S_w_db = librosa.amplitude_to_db(mag_wiener, ref=np.max)\n",
    "librosa.display.specshow(S_w_db, sr=sr, hop_length=HOP_LENGTH, \n",
    "                         x_axis='time', y_axis='log', ax=ax[1])\n",
    "ax[1].set_title('Wiener-Denoised Spectrogram')\n",
    "ax[1].invert_yaxis()\n",
    "\n",
    "plt.suptitle('Spectrogram: Before vs. After Wiener Filtering', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21597bb-a5d1-4add-8184-7f59321c7870",
   "metadata": {},
   "source": [
    "### Key Concepts: Normalization & Dynamic Range Compression\n",
    "\n",
    "- **Peak vs. RMS Normalization**  \n",
    "  - **Peak normalization** rescales the entire signal so its maximum absolute sample reaches a target level (e.g. –1 dBFS).  \n",
    "  - **RMS normalization** adjusts the overall loudness by matching the root-mean-square energy to a target (e.g. –18 LUFS), yielding a more perceptually consistent level.\n",
    "\n",
    "- **Dynamic Range Compression**  \n",
    "  A compressor reduces the level of loud passages above a set threshold, “squashing” the dynamic range and bringing quieter and louder parts closer together.  \n",
    "\n",
    "  - **Threshold**: the level (in dB) above which gain reduction begins.  \n",
    "  - **Ratio**: how much the signal above threshold is turned down (e.g. 4:1 means 4 dB in → 1 dB out).  \n",
    "  - **Attack time**: how quickly the compressor kicks in after the signal exceeds the threshold (milliseconds).  \n",
    "  - **Release time**: how quickly it stops compressing once the signal falls below the threshold (milliseconds).  \n",
    "\n",
    "Understanding and tuning these parameters allows you to control loudness, punch, and perceived “warmth” or “presence” in your audio.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee817a90-55cd-41af-bc63-6d3ca547a68b",
   "metadata": {},
   "source": [
    "## Demo 3: Dynamic Range Compression\n",
    "\n",
    "In this demo you'll apply a simple compressor to a percussive audio clip and visualize how it tames peaks and reduces dynamic range.\n",
    "\n",
    "**What the code does:**\n",
    "1. **Loads** your audio file from `sounds/`.\n",
    "2. **Normalizes** it so the peak level is 0 dBFS.\n",
    "3. **Computes** a sample-by-sample envelope follower using your attack & release times.\n",
    "4. **Applies** compression above your threshold with the specified ratio.\n",
    "5. **Smooths** the gain changes, adds any makeup gain, and **reconstructs** the compressed signal.\n",
    "6. **Plays back** both the original and compressed audio.\n",
    "7. **Plots**  \n",
    "   - The input vs. output level envelopes over time, with the shaded area showing gain reduction  \n",
    "   - The static gain-reduction curve (input level → reduction in dB)\n",
    "\n",
    "**How to use:**\n",
    "- Edit the **USER SETTINGS** at the top of the code cell:\n",
    "  - `FILENAME` &mdash; your clip in `sounds/`  \n",
    "  - `THRESHOLD_DB` &mdash; compressor threshold (dBFS), e.g. -60 … 0  \n",
    "  - `RATIO` &mdash; how hard to compress above threshold (> 1.0)  \n",
    "  - `ATTACK_MS`, `RELEASE_MS` &mdash; envelope times in milliseconds (> 0)  \n",
    "  - `OUTPUT_GAIN_DB` &mdash; any makeup gain after compression (dB)  \n",
    "- Run the cell.\n",
    "\n",
    "**What to observe:**\n",
    "- **Audio A/B** &mdash; does the compressed version sound more even and controlled?  \n",
    "- **Envelope plot** &mdash; see how peaks above the threshold are “pulled down” by the compressor (shaded area).  \n",
    "- **Gain curve** &mdash; confirms the static behavior: input levels above `THRESHOLD_DB` are reduced by `(1 – 1/ratio)` of their excess.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863e742-0be7-4573-b910-7875c83594cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── USER SETTINGS ────────────────────────────────────────────────────────────────\n",
    "FILENAME        = 'drum_hit3.wav'   # ← place your audio file in `sounds/`\n",
    "THRESHOLD_DB    = -20.0             # ← compressor threshold in dBFS (e.g. -60 … 0)\n",
    "RATIO           = 4.0               # ← compression ratio (>1.0)\n",
    "ATTACK_MS       = 10.0              # ← attack time in milliseconds (>0)\n",
    "RELEASE_MS      = 100.0             # ← release time in milliseconds (>0)\n",
    "OUTPUT_GAIN_DB  = 0.0               # ← makeup gain after compression in dB (e.g. -6 … +6)\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "from pathlib import Path\n",
    "\n",
    "# ── CONFIG (don’t edit below here) ───────────────────────────────────────────────\n",
    "SOUNDS_DIR = Path('sounds')\n",
    "y, sr = librosa.load(str(SOUNDS_DIR / FILENAME), sr=None)\n",
    "# normalize to peak = 1\n",
    "y = y / np.max(np.abs(y) + 1e-16)\n",
    "\n",
    "# envelope follower coefficients\n",
    "attack_tc  = np.exp(-1.0 / (sr * (ATTACK_MS  / 1000.0)))\n",
    "release_tc = np.exp(-1.0 / (sr * (RELEASE_MS / 1000.0)))\n",
    "\n",
    "# prepare arrays\n",
    "env      = np.zeros_like(y)\n",
    "gain_db  = np.zeros_like(y)\n",
    "prev_env = 0.0\n",
    "\n",
    "# compute envelope and static gain\n",
    "for n, sample in enumerate(y):\n",
    "    x = abs(sample)\n",
    "    if x > prev_env:\n",
    "        prev_env = attack_tc  * prev_env + (1-attack_tc)  * x\n",
    "    else:\n",
    "        prev_env = release_tc * prev_env + (1-release_tc) * x\n",
    "    env[n] = prev_env\n",
    "    level_db = 20 * np.log10(prev_env + 1e-8)\n",
    "    if level_db > THRESHOLD_DB:\n",
    "        # apply compression above threshold\n",
    "        comp_db = THRESHOLD_DB + (level_db - THRESHOLD_DB)/RATIO\n",
    "        gain_db[n] = comp_db - level_db\n",
    "    else:\n",
    "        gain_db[n] = 0.0\n",
    "\n",
    "# smooth gain with release (optional but recommended)\n",
    "smoothed_gain_db = np.copy(gain_db)\n",
    "prev_g = 0.0\n",
    "for n, g in enumerate(gain_db):\n",
    "    if g < prev_g:\n",
    "        prev_g = attack_tc  * prev_g + (1-attack_tc)  * g\n",
    "    else:\n",
    "        prev_g = release_tc * prev_g + (1-release_tc) * g\n",
    "    smoothed_gain_db[n] = prev_g\n",
    "\n",
    "# apply makeup gain\n",
    "total_gain_db = smoothed_gain_db + OUTPUT_GAIN_DB\n",
    "total_gain_lin = 10**(total_gain_db / 20)\n",
    "\n",
    "y_comp = y * total_gain_lin\n",
    "\n",
    "# ── PLAYBACK ───────────────────────────────────────────────────────────────────\n",
    "print(\"▶️ Original Audio\")\n",
    "display(Audio(data=y,       rate=sr, autoplay=False))\n",
    "print(\"▶️ Compressed Audio\")\n",
    "display(Audio(data=y_comp,  rate=sr, autoplay=False))\n",
    "\n",
    "# ── PLOTS ───────────────────────────────────────────────────────────────────────\n",
    "times = np.arange(len(y)) / sr\n",
    "\n",
    "# 1) Envelope and gain reduction\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(times, 20*np.log10(env + 1e-8),      label='Input Level (dBFS)')\n",
    "plt.plot(times, 20*np.log10(env + 1e-8) + smoothed_gain_db, \n",
    "         label='Output Level (dBFS)')\n",
    "plt.fill_between(times, \n",
    "                 20*np.log10(env + 1e-8), \n",
    "                 20*np.log10(env + 1e-8) + smoothed_gain_db,\n",
    "                 color='C1', alpha=0.3,\n",
    "                 label='Gain Reduction')\n",
    "plt.title('Compressor Envelope & Gain Reduction')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Level (dB)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) Gain reduction curve\n",
    "plt.figure(figsize=(6,4))\n",
    "input_levels = np.linspace(-80, 0, 100)\n",
    "gain_curve = np.where(\n",
    "    input_levels > THRESHOLD_DB,\n",
    "    (THRESHOLD_DB + (input_levels - THRESHOLD_DB)/RATIO) - input_levels,\n",
    "    0.0\n",
    ")\n",
    "plt.plot(input_levels, gain_curve, linewidth=2)\n",
    "plt.title('Static Gain Reduction Curve')\n",
    "plt.xlabel('Input Level (dBFS)')\n",
    "plt.ylabel('Gain Reduction (dB)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ac082-d2d9-433a-9e9d-dcb8be7f1b1d",
   "metadata": {},
   "source": [
    "### Key Concept: Filtering\n",
    "\n",
    "- **FIR vs. IIR Filters**  \n",
    "  - **FIR (Finite Impulse Response):**  \n",
    "    - Non-recursive, inherently stable, linear‐phase (if symmetric taps).  \n",
    "    - Design by placing a window on an ideal impulse response.  \n",
    "  - **IIR (Infinite Impulse Response):**  \n",
    "    - Recursive, can achieve sharp cutoffs with fewer coefficients.  \n",
    "    - Generally nonlinear phase, may require care for stability.\n",
    "\n",
    "- **Window Design**  \n",
    "  - **Rectangular (boxcar):**  \n",
    "    - Simple, narrow main-lobe but large side-lobes (poor stop-band attenuation).  \n",
    "  - **Hamming / Hann:**  \n",
    "    - Wider main-lobe, much lower side-lobes (better suppression of distant frequencies).  \n",
    "  - **Blackman / Blackman–Harris:**  \n",
    "    - Even wider main-lobe, extremely low side-lobes (excellent stop-band performance).\n",
    "\n",
    "Filtering trade-offs are often between transition-band width (main-lobe) vs. stop-band attenuation (side-lobes) and phase behavior.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e17e55-15f9-4e60-bd8a-a0746ec81293",
   "metadata": {},
   "source": [
    "## Demo 4: FIR vs. IIR Low-Pass Filtering\n",
    "\n",
    "In this demo you’ll design and compare two simple low-pass filters—a windowed FIR filter and a Butterworth IIR filter—and apply them to an audio clip.\n",
    "\n",
    "### What the code does:\n",
    "1. **Load** your chosen audio file (normalized to peak = 1).  \n",
    "2. **Design**:  \n",
    "   - An **FIR** filter of order `FIR_ORDER` with cutoff `CUTOFF_FREQ` Hz using the specified `WINDOW_TYPE`.  \n",
    "   - An **IIR** Butterworth filter of order `IIR_ORDER` with the same cutoff.  \n",
    "3. **Plot** their impulse responses side by side, so you can see the FIR taps vs. the IIR’s recursive response.  \n",
    "4. **Plot** their magnitude responses (frequency-domain) on the same axes to compare pass-band flatness and stop-band attenuation.  \n",
    "5. **Apply** both filters (zero-phase via `filtfilt`) to your clip and display audio players for:  \n",
    "   - Original  \n",
    "   - FIR-filtered  \n",
    "   - IIR-filtered  \n",
    "6. **Plot** the first 0.1 s of each waveform overlaid to illustrate how each filter shapes the time-domain signal.\n",
    "\n",
    "---\n",
    "\n",
    "### How to use:\n",
    "- Edit the **USER SETTINGS** at the top of the code cell:  \n",
    "  - `FILENAME`: name of your test audio file in `sounds/`.  \n",
    "  - `CUTOFF_FREQ`: cutoff frequency in Hz (must satisfy `0 < CUTOFF_FREQ < sr/2`).  \n",
    "  - `FIR_ORDER`: order of the FIR filter (even integer ≥ 2).  \n",
    "  - `WINDOW_TYPE`: window for the FIR design (`'boxcar'`, `'hann'`, `'hamming'`, `'blackman'`).  \n",
    "  - `IIR_ORDER`: order of the IIR Butterworth filter (integer ≥ 1).  \n",
    "- Run the cell to:  \n",
    "  1. See the impulse-response and frequency-response plots.  \n",
    "  2. Listen to the original, FIR-filtered, and IIR-filtered audio.  \n",
    "  3. Inspect the overlaid waveform for the first 0.1 s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf1275-f5c9-44c0-a46b-1097c4642525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── USER SETTINGS ────────────────────────────────────────────────────────────────\n",
    "FILENAME      = 'drum_hit3.wav'   # ← place your test audio file in `sounds/`\n",
    "CUTOFF_FREQ   = 1000.0            # ← cutoff frequency in Hz (0 < CUTOFF_FREQ < sr/2)\n",
    "FIR_ORDER     = 64                # ← order of FIR filter (even integer ≥ 2)\n",
    "WINDOW_TYPE   = 'hamming'         # ← window for FIR ('boxcar','hann','hamming','blackman')\n",
    "IIR_ORDER     = 4                 # ← order of IIR Butterworth filter (integer ≥ 1)\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import firwin, butter, freqz, filtfilt\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "\n",
    "# ── CONFIG (don’t edit below here) ───────────────────────────────────────────────\n",
    "SOUNDS_DIR = Path('sounds')\n",
    "audio_path = SOUNDS_DIR / FILENAME\n",
    "\n",
    "# 1) Load audio\n",
    "y, sr = librosa.load(str(audio_path), sr=None)\n",
    "y = y / np.max(np.abs(y) + 1e-16)  # normalize peak = 1\n",
    "\n",
    "# 2) Design FIR low-pass filter\n",
    "nyq = sr / 2\n",
    "fir_coeff = firwin(\n",
    "    numtaps=FIR_ORDER + 1,\n",
    "    cutoff=CUTOFF_FREQ / nyq,\n",
    "    window=WINDOW_TYPE\n",
    ")\n",
    "\n",
    "# 3) Design IIR Butterworth low-pass filter\n",
    "b_iir, a_iir = butter(\n",
    "    N=IIR_ORDER,\n",
    "    Wn=CUTOFF_FREQ / nyq,\n",
    "    btype='lowpass'\n",
    ")\n",
    "\n",
    "# 4) Plot impulse responses\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.stem(np.arange(len(fir_coeff)), fir_coeff, linefmt='C0-', markerfmt='C0o', basefmt=\" \", label='FIR taps')\n",
    "imp_iir = np.zeros(len(fir_coeff))\n",
    "imp_iir[0] = 1.0\n",
    "h_iir = filtfilt(b_iir, a_iir, imp_iir)\n",
    "plt.plot(h_iir, 'C1-', linewidth=2, label='IIR impulse response')\n",
    "plt.title('Impulse Responses')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 5) Plot frequency responses\n",
    "w_fir, h_fir = freqz(fir_coeff, worN=8000)\n",
    "w_iir, h_iir = freqz(b_iir, a_iir, worN=8000)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(w_fir * sr / (2*np.pi), 20*np.log10(np.abs(h_fir) + 1e-8), label='FIR')\n",
    "plt.plot(w_iir * sr / (2*np.pi), 20*np.log10(np.abs(h_iir) + 1e-8), label='IIR')\n",
    "plt.title('Magnitude Responses')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude (dB)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(-80, 5)\n",
    "plt.show()\n",
    "\n",
    "# 6) Apply filters (zero-phase)\n",
    "y_fir = filtfilt(fir_coeff, [1.0], y)\n",
    "y_iir = filtfilt(b_iir, a_iir, y)\n",
    "\n",
    "# 7) Playback\n",
    "print(\"▶️ Original Audio\")\n",
    "display(Audio(data=y,      rate=sr, autoplay=False))\n",
    "print(\"▶️ FIR-Filtered Audio\")\n",
    "display(Audio(data=y_fir,  rate=sr, autoplay=False))\n",
    "print(\"▶️ IIR-Filtered Audio\")\n",
    "display(Audio(data=y_iir,  rate=sr, autoplay=False))\n",
    "\n",
    "# 8) Plot filtered waveforms (first 0.1s)\n",
    "t = np.arange(len(y)) / sr\n",
    "n_plot = int(0.1 * sr)\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(t[:n_plot], y[:n_plot],   label='Original', alpha=0.7)\n",
    "plt.plot(t[:n_plot], y_fir[:n_plot],label='FIR',      alpha=0.7)\n",
    "plt.plot(t[:n_plot], y_iir[:n_plot],label='IIR',      alpha=0.7)\n",
    "plt.title('Waveform Comparison (first 0.1s)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22457fe9-ff6a-4cb4-bf07-762bb73a58da",
   "metadata": {},
   "source": [
    "### 🛠 Exercise: Mains-Hum Removal Filter\n",
    "\n",
    "**Task:**  \n",
    "Implement a band-stop (notch) filter to remove mains hum (50 Hz or 60 Hz) from a voice recording.\n",
    "\n",
    "**Steps:**\n",
    "1. **Design** a narrow IIR notch filter centered at the line frequency (50 Hz or 60 Hz).  \n",
    "2. **Load** a WAV file containing speech with mains hum.  \n",
    "3. **Apply** your notch filter to the noisy signal.  \n",
    "4. **Compare** before/after by:  \n",
    "   - Plotting the **magnitude response** of your notch filter.  \n",
    "   - Displaying **spectrograms** of the noisy vs. filtered audio.  \n",
    "   - Playing back both versions with the built-in audio players.\n",
    "\n",
    "**Deliverables:**\n",
    "- A plot of your notch filter’s frequency response, showing deep attenuation at the target line frequency.  \n",
    "- Two spectrograms (pre- and post-filter) highlighting the removed hum component.  \n",
    "- Audio players to listen to the original vs. filtered signal so you can confirm the hum has been attenuated without severely affecting speech quality.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f30c17-4738-4fe5-a0a2-6182ac0f7b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
